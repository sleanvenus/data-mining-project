{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refers to https://stackabuse.com/introduction-to-pytorch-for-classification/\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'sex','native-country']\n",
    "numerical_columns = ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "outputs = ['exceeds50K']\n",
    "\n",
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "categorical_data = np.stack([dataset[cat].cat.codes.values for cat in categorical_columns], 1)\n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64).to(device)\n",
    "\n",
    "numerical_data = np.stack([dataset[col].values for col in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float).to(device)\n",
    "\n",
    "outputs = torch.tensor(dataset[outputs].values).flatten().to(device)\n",
    "\n",
    "print(categorical_data.shape)\n",
    "print(numerical_data.shape)\n",
    "print(outputs.shape)\n",
    "\n",
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)\n",
    "\n",
    "total_records = outputs.shape[0]\n",
    "test_records = int(total_records * .1)\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "numerical_train_data = numerical_data[:total_records-test_records]\n",
    "numerical_test_data = numerical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = Model(categorical_embedding_sizes, numerical_data.shape[1], 2, [200,100,50], p=0.4).cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 1000\n",
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data, numerical_train_data)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%100 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "        y_val = model(categorical_test_data, numerical_test_data)\n",
    "        y_val = np.argmax(y_val.detach().cpu().numpy(), axis=1)\n",
    "       \n",
    "        acc = accuracy_score(test_outputs.cpu().numpy(), y_val)\n",
    "        f1=f1_score(test_outputs.cpu().numpy(), y_val, average='weighted')\n",
    "        print(\"acc: %.2f%%\" % (acc * 100.0))\n",
    "        print(\"f1: %.2f%%\" % (f1 * 100.0))\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
